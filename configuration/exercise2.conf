name: Exercise2
  
provider {
    type: aws
    accessKeyId: ${?AWS_ACCESS_KEY_ID}
    secretAccessKey: ${?AWS_SECRET_ACCESS_KEY}
    region: us-east-1
    subnetId: subnet-751e8358
    securityGroupsIds: sg-40d1f83d
    instanceNamePrefix: director
    rootVolumeSizeGB: 50
    rootVolumeType: gp2
    associatePublicIpAddresses: true
    instanceNamePrefix: cloudera-director
}
  
ssh {
    username: ec2-user
    privateKey: /home/ec2-user/.ssh/id_rsa
}
  
common-instance-properties {
			   image: ami-2051294a 

			   tags {
			   	owner: kevin.delia
			   }

			   bootstrapScriptPath: "/home/ec2-user/java8-bootstrap-script.sh"

			   normalizeInstance: true
}

instances {
    m3 : ${common-instance-properties} {
        type: m3.large
    }
  
    m3x : ${common-instance-properties} {
        type: m3.xlarge
    }
  
    m4x : ${common-instance-properties} {
        type: m4.xlarge
    }
}
  
cloudera-manager {
    instance: ${instances.m4x} {
        tags {
  
        }
    }
  
    repository: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5.9/"
    repositoryKeyUrl: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/RPM-GPG-KEY-cloudera"
    enableEnterpriseTrial: true

    # Prefix used to launch instances
    instanceNamePrefix: Exercise2

    # Override the default password
    password: Exercise2_password
    
    # Disable the default installation of Java 7
    javaInstallationStrategy: NONE

    # Install the unlimited strength JCE policy files for higher levels of encryption.
    # Prior to setting this to true, confirm that you understand the legal ramifications
    # of using unlimited JCE policy files in your country.
    unlimitedJce: true

    # An administrative Kerberos account capable of creating principals on the KDC that
    # Cloudera Manager will be using. This will typically be in the format:
    #    Principal@YOUR.KDC.REALM
    #
    # this value can be found in the kadm5.acl file
    krbAdminUsername: "cloudera-scm/admin@EXERCISE2"

    # The password for the administrative Kerberos account.
    krbAdminPassword: "cloudera"

    configs {
        CLOUDERA_MANAGER {
			 allow_usage_data: false
			 custom_banner_html: "Cloudera Director - Exercise 2"

			 # Kerberos configuration
			 # The encoding types come from the kdc.conf file
			 # The host is the internal IP for the CD instance
			 KDC_TYPE: "MIT KDC"
			 KDC_HOST: "172.31.52.56"
			 SECURITY_REALM: "EXERCISE2"
			 KRB_MANAGE_KRB5_CONF: true
			 KRB_ENC_TYPES: "aes256-cts aes128-cts arcfour-hmac"
        }
  
        CLOUDERA_MANAGEMENT_SERVICE {
  
        }
  
        SERVICEMONITOR {
  		       firehose_heapsize: 536870912
        }
  
        HOSTMONITOR {
  		    firehose_heapsize: 536870912
        }
  
        EVENTSERVER {
  		     event_server_heapsize: 536870912
        }
  
        REPORTSMANAGER {
  		        headlamp_heapsize: 536870912
        }
  
        ALERTPUBLISHER {
  
        }
  
        NAVIGATORMETASERVER {
  			     allow_usage_data: false
			     navigator_heapsize: 536870912
        }
  
        NAVIGATOR {
		   navigator_heapsize: 536870912  
        }
  
        HOSTS {
	      # The bootstrap script installs this version
	      java_home: /opt/jdk1.8.0_60
        }
    }
}
   
cluster {
    products {
        CDH: 5
    }
  
    parcelRepositories: ["http://archive.cloudera.com/cdh5/parcels/5.9/"]
  
    services: [HDFS, YARN, ZOOKEEPER, HIVE, OOZIE, HUE, IMPALA, SPARK_ON_YARN]
  
    # Service-wide configurations per-service
    configs {
    	    # HDFS fencing should be set to true for HA configurations
	    HDFS {
	    	 dfs_ha_fencing_methods: "shell(true)"
		 }
	}
  
    master1 {
        count: 1
  
        instance: ${instances.m3x} {
            tags {
  
            }
        }
  
        roles {
	      HDFS: [NAMENODE, JOURNALNODE, FAILOVERCONTROLLER]
	      YARN: [RESOURCEMANAGER]
	      ZOOKEEPER: [SERVER]
	      HIVE: [GATEWAY]
	      SPARK_ON_YARN: [GATEWAY]
	      }

        # Role-specific configs
        configs {
            HDFS {
                NAMENODE {
                    # Namenode-specific configs here
		    dfs_namenode_edits_dir: /data1/dfs/nn
		    namenode_java_heapsize: 536870912
		    # NameNode nameservice, autofailover, and quorum journal
		    # name must be configured for high availability
                    dfs_federation_namenode_nameservice: hanameservice
                    autofailover_enabled: true
                    dfs_namenode_quorum_journal_name: hanameservice
                }
		JOURNALNODE {
                    # Journalnode-specific configs here
		    dfs_journalnode_edits_dir: /data0/dfs/jn
                }
            }
	    YARN {
	    	 RESOURCEMANAGER {
		 resource_manager_java_heapsize: 536870912
		 }
	    }
	    ZOOKEEPER {
	    	      SERVER {
		      	     dataDir: "/data1/zookeeper"
			     dataLogDir: "/data1/zookeeper"
                }
	    }
        }
    }
   
    master2 {
        count: 1
  
        instance: ${instances.m3x} {
            tags {
  
            }
        }
  
        roles {
	      HDFS: [NAMENODE, JOURNALNODE, FAILOVERCONTROLLER]
	      YARN: [RESOURCEMANAGER]
	      ZOOKEEPER: [SERVER]
	      HIVE: [GATEWAY]
	      SPARK_ON_YARN: [GATEWAY]
        }
  
        # Role-specific configs
        configs {
            HDFS {
                NAMENODE {
                    # Namenode-specific configs here
		    dfs_namenode_edits_dir: /data1/dfs/nn
		    namenode_java_heapsize: 536870912
                }
		JOURNALNODE {
                    # Journalnode-specific configs here
		    dfs_journalnode_edits_dir: /data0/dfs/jn
                }
            }
	    YARN {
	    	 RESOURCEMANAGER {
		 resource_manager_java_heapsize: 536870912
		 }
	    }
	    ZOOKEEPER {
	    	      SERVER {
		      	     dataDir: "/data1/zookeeper"
			     dataLogDir: "/data1/zookeeper"
                }
	    }
        }
    }
  
    master3 {
        count: 1
  
        instance: ${instances.m3x} {
            tags {
  
            }
        }
  
        roles {
	      # Insert role types here
	      HDFS: [BALANCER, JOURNALNODE]
	      ZOOKEEPER: [SERVER]
	      HIVE: [HIVEMETASTORE, GATEWAY]
	      SPARK_ON_YARN: [GATEWAY]
	      IMPALA: [STATESTORE, CATALOGSERVER]
        }
  
        # Role-specific configs
        configs {
            HDFS {
		JOURNALNODE {
                    # Journalnode-specific configs here
		    dfs_journalnode_edits_dir: /data0/dfs/jn
                }
            }
           HIVE {
                HIVEMETASTORE {
                    hive_metastore_java_heapsize: 536870912
                }
                HIVESERVER2 {
                    hiveserver2_java_heapsize: 536870912
                }
            }
	    IMPALA {
	    	   CATALOGSERVER {
		   		 catalogd_embedded_jvm_heapsize: 536870912
		   }
	    }
        }
    }
 
    worker {
        count: 3
        minCount: 3
  
        instance: ${instances.m3} {
            tags {
  
            }
        }
  
        roles {
	      # Insert role types here
	      HDFS: [DATANODE]
	      YARN: [NODEMANAGER]
	      HIVE: [GATEWAY]
	      IMPALA: [IMPALAD]
	      SPARK_ON_YARN: [GATEWAY]
        }
  
        # Role-specific configs
        configs {
            HDFS {
                DATANODE {
                   # Datanode-specific configs here
		   dfs_data_dir_list: /data0/dfs/dn
		   datanode_java_heapsize: 536870912
		   dfs_datanode_failed_volumes_tolerated: 0
                }
            }
	    YARN {
	    	 NODEMANAGER {
		 	     node_manager_java_heapsize: 536870912
			     yarn_nodemanager_local_dirs: /data0/yarn/nm
			     yarn_nodemanager_log_dirs: /data0/yarn/container-logs
		 }
	    }
	    IMPALA {
	    	   IMPALAD {
		   	   scratch_dirs: /data0/impala/impalad
			   impalad_memory_limit: 536870912
		   }
	    }
        }
    }
  
    gateway {
        count: 1
  
        instance: ${instances.m4x} {
            tags {
  
            }
        }
  
        roles {
            # Insert role types here
	    HDFS: [HTTPFS, GATEWAY]
	    YARN: [JOBHISTORY, GATEWAY]
	    HIVE: [HIVESERVER2, GATEWAY]
	    OOZIE: [OOZIE_SERVER]
	    HUE: [HUE_SERVER]
	    SPARK_ON_YARN: [SPARK_YARN_HISTORY_SERVER, GATEWAY]
        }
  
        # Role-specific configs
        configs {
            OOZIE {
                OOZIE_SERVER {
                    oozie_java_heapsize: 536870912
                }
            }
        }
    }
}
