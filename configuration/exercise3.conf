name: Exercise3
 
provider {
    type: aws
    # The next two values are set in the environment prior to running the script.
    # They should be enclosed in double-quotes.
    accessKeyId: ${?AWS_ACCESS_KEY_ID}
    secretAccessKey: ${?AWS_SECRET_ACCESS_KEY}
    region: us-east-1
    subnetId: subnet-751e8358
    securityGroupsIds: sg-40d1f83d
    instanceNamePrefix: director
    rootVolumeSizeGB: 50
    rootVolumeType: gp2
    associatePublicIpAddresses: true
}
 
ssh {
    username: ec2-user
    privateKey: /home/ec2-user/.ssh/id_rsa
}

common-instance-properties {
			   image: ami-2051294a 

			   tags {
			   	owner: kevin.delia
			   }

			   normalizeInstance: true
}

# Definitions of the instances used by Cloudera Director
instances {
    m3 : ${common-instance-properties} {
        type: m3.large
    }
 
    m3x : ${common-instance-properties} {
        type: m3.xlarge
    }
 
    m4x : ${common-instance-properties} {
        type: m4.xlarge
    }
}
 
cloudera-manager {
    instance: ${instances.m4x} {
        tags {
        }
    }
 
    repository: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5.9/"
    repositoryKeyUrl: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/RPM-GPG-KEY-cloudera"

    enableEnterpriseTrial: true
 
    configs {
        CLOUDERA_MANAGER {
			 allow_usage_data: false
			 custom_banner_html: "Cloudera Director - Exercise 3"
        }
 
        CLOUDERA_MANAGEMENT_SERVICE {
 
        }
 
        SERVICEMONITOR {
		       firehose_heapsize: 536870912
	}
 
        HOSTMONITOR {
		    firehose_heapsize: 536870912
        }
 
        EVENTSERVER {
		     event_server_heapsize: 536870912
        }
 
        REPORTSMANAGER {
		        headlamp_heapsize: 536870912
        }
 
        ALERTPUBLISHER {
 
        }
 
        NAVIGATORMETASERVER {
			     allow_usage_data: false
			     navigator_heapsize: 536870912
        }
 	# Under navigatorauditserver
        NAVIGATOR {
		   navigator_heapsize: 536870912
        }
 
        HOSTS {
 
        }
    }
}
  
cluster {
    products {
        CDH: 5
    }
 
    postCreateScripts: ["""#!/bin/sh
    
    # This is an embedded post-creation script that runs as root and can be used to
    # customize the cluster after it has been created. This will run only once,
    # at a cluster level, on an arbitrary cluster instance.

    # If the exit code is not zero Cloudera Director will fail

    # Post-creation scripts also have access to the following environment variables:

    #    DEPLOYMENT_HOST_PORT
    #    ENVIRONMENT_NAME
    #    DEPLOYMENT_NAME
    #    CLUSTER_NAME
    #    CM_USERNAME
    #    CM_PASSWORD

    # Step 3 for the GPLEXTRAS installation
    yum install lzo
    exit 0
    """

    parcelRepositories: ["http://archive.cloudera.com/cdh5/parcels/5.9/",
    			"https://archive.cloudera.com/gplextras5/parcels/{latest_supported}"]
 
    services: [HDFS, YARN, ZOOKEEPER, HIVE, OOZIE, HUE]
 
    # Service-wide configurations per-service
    configs {
 
    }
 
    master {
        count: 1
 
        instance: ${instances.m3x} {
            tags {
 
            }
        }
 
        roles {
	      HDFS: [NAMENODE, SECONDARYNAMENODE, HTTPFS, BALANCER, GATEWAY]
	      YARN: [RESOURCEMANAGER, JOBHISTORY, GATEWAY]
	      ZOOKEEPER: [SERVER]
	      HIVE: [HIVEMETASTORE, HIVESERVER2]
	      OOZIE: [OOZIE_SERVER]
	      HUE: [HUE_SERVER]
        }
 
        # Role-specific configs
        configs {
            HDFS {
	    	 core_site_safety_valve:
				"""
				<property>
					<name>fs.s3a.access.key</name>
					<description>${?AWS_ACCESS_KEY_ID}</description>
				</property>
				<property>
					<name>fs.s3a.secret.key</name>
					<description>${?AWS_SECRET_ACCESS_KEY}</description>
				</property>
				"""
                NAMENODE {
                    # Namenode-specific configs here
		    dfs_namenode_edits_dir: /data1/dfs/nn
		    namenode_java_heapsize: 536870912
                }
		SECONDARYNAMENODE {
                    # Secondarynamenode-specific configs here
		    fs_checkpoint_dir_list: /data1/dfs/snn
		    secondary_namenode_java_heapsize: 536870912
                }
            }
	    YARN {
	    	 RESOURCEMANAGER {
		 resource_manager_java_heapsize: 536870912
		 }
	    }
	    ZOOKEEPER {
	    	      SERVER {
		      	     dataDir: "/data1/zookeeper"
			     dataLogDir: "/data1/zookeeper"
			     }
	    }
	    HIVE {
	    	 HIVEMETASTORE {
		 	       hive_metastore_java_heapsize: 536870912
			       }
		 HIVESERVER2 {
		 	     hiveserver2_java_heapsize: 536870912
			     }
		 }
            OOZIE {
                OOZIE_SERVER {
                    oozie_java_heapsize: 536870912
                }
            }
        }
    } # end master
  
    worker {
        count: 3
        minCount: 3
 
        instance: ${instances.m3} {
            tags {
 
            }
        }
 
        roles {
	      HDFS: [DATANODE]
	      YARN: [NODEMANAGER]
	      HIVE: [GATEWAY]
        }
 
        # Role-specific configs
        configs {
            HDFS {
                DATANODE {
                   # Datanode-specific configs here
		   dfs_data_dir_list: /data0/dfs/dn
		   datanode_java_heapsize: 536870912
		   dfs_datanode_failed_volumes_tolerated: 0
                }
            }
	    YARN {
	    	 NODEMANAGER {
		 	     node_manager_java_heapsize: 536870912
			     yarn_nodemanager_local_dirs: /data0/yarn/nm
			     yarn_nodemanager_log_dirs: /data0/yarn/container-logs
		 }
	    }
        }
    }
}